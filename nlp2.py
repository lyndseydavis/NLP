from textblob import TextBlob
import nltk
from pathlib import Path
import pandas as pd


# eliminate stop words when analyzing code (ex: the, and, etc.-look at powerpoint for list of words
# stopwords = a list, so you can add to it

# nltk.download("stopwords")
from nltk.corpus import stopwords

stops = stopwords.words("english")
# print(stops) #prints out the list of "stop words" - these are the words that you may not want to be considered while doing text analysis

blob = TextBlob("Today is a beautiful day.")

# print(blob.words)
"""
cleanlist = []
for words in blob.words: #how to create a new list of words that don't include any of the words in stop words
    if words not in stops:
        cleanlist.append(words)
print(cleanlist)
"""

cleanlist = [word for word in blob.words if word not in stops]
# print(cleanlist)

blob = TextBlob(Path("RomeoAndJuliet.txt").read_text())


# print(blob.word_counts["juliet"])

# print(blob.noun_phrases.count("lady capulet"))

more_stops = ["thee", "thy", "thou"]

stops += more_stops

items = blob.word_counts.items()
# print(items) #this counts how many times each word is used, returns as a tuple

# use a list comprehension to eliminate any tuples containing stop words
items = [
    i for i in items if i[0] not in stops
]  # i[0] = first element of the tuple as it cycles through. checks to see if the word is in the stops list or not
print(items[:10])

from operator import itemgetter

sorted_items = sorted(items)
print(sorted_items[:10])  # this sorts words alphabetically

sorted_items = sorted(
    items, key=itemgetter(1), reverse=True
)  # itemgetter(1) = second element in each of the touples
# this sorts tuples by frequency # in decending order
print(sorted_items[:10])

top20 = sorted_items[:20]

df = pd.DataFrame(
    top20, columns=["Word", "Count"]
)  # creates a dataframe for the top 20 results
print(df)

import matplotlib as plt

df.plot.bar(x="Word", y="Count", legend=False)

plt.gcf().tight_layout()  # need to fix this???

plt.show()
